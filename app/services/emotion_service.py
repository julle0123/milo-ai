# emotion_service.py
from typing import List, Dict
import json
from app.models.user import User
from app.core.client import llm
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
from app.models.daily_emotion_report import DailyEmotionReport
# ----------------------
# ë¬¸ì¥ ë‹¨ìœ„ ê°ì • ë¶„ë¥˜ìš© (6ì¢…)
# ----------------------

EMOTION_CATEGORIES = ["ê¸°ì¨", "ë¶ˆì•ˆ", "ë¶„ë…¸", "ìŠ¬í””", "ìƒì²˜", "ë‹¹í™©"]

def analyze_emotion_gpt(user_input: str) -> str:
    prompt = (
        "ë‹¤ìŒ ë¬¸ì¥ì˜ ëŒ€í‘œ ê°ì •ì„ ë°˜ë“œì‹œ ì•„ë˜ 6ê°œ ì¤‘ í•˜ë‚˜ë¡œë§Œ í•œê¸€ í•œ ë‹¨ì–´ë¡œ ì¶œë ¥í•´ì¤˜.\n"
        "ê¸°ì¨, ë¶ˆì•ˆ, ë¶„ë…¸, ìŠ¬í””, ìƒì²˜, ë‹¹í™© ì¤‘ íƒ1\n"
        f"ë¬¸ì¥: {user_input}\nê°ì •: "
    )
    emotion = llm.invoke(prompt).content.strip()
    if emotion not in EMOTION_CATEGORIES:
        emotion = "ë¶ˆì•ˆ"
    return f"[ê°ì •: {emotion}] {user_input}"

def extract_emotion_label(user_input: str) -> str:
    prompt = (
        "ë‹¤ìŒ ë¬¸ì¥ì˜ ëŒ€í‘œ ê°ì •ì„ ë°˜ë“œì‹œ ì•„ë˜ 6ê°œ ì¤‘ í•˜ë‚˜ë¡œë§Œ í•œê¸€ í•œ ë‹¨ì–´ë¡œ ì¶œë ¥í•´ì¤˜.\n"
        "ê¸°ì¨, ë¶ˆì•ˆ, ë¶„ë…¸, ìŠ¬í””, ìƒì²˜, ë‹¹í™© ì¤‘ íƒ1\n"
        f"ë¬¸ì¥: {user_input}\nê°ì •: "
    )
    emotion = llm.invoke(prompt).content.strip()
    return emotion if emotion in EMOTION_CATEGORIES else "ë¶ˆì•ˆ"

# ----------------------
# í•˜ë£¨ì¹˜ ê°ì • ë¶„ì„ ë¦¬í¬íŠ¸ìš© (6ì¢… ë¶„ì„ â†’ ëŒ€í‘œ ê°ì • 5ì¢… ë³€í™˜)
# ----------------------

def convert_to_main_emotion(score_dict: Dict[str, float]) -> str:
    five_emotion_scores = {
        "ê¸°ì¨": score_dict.get("joy", 0.0),
        "ìŠ¬í””": score_dict.get("sadness", 0.0),
        "ë¶„ë…¸": score_dict.get("anger", 0.0),
        "ë¶ˆì•ˆ": score_dict.get("anxiety", 0.0),
        "ì•ˆì •": score_dict.get("stable", 0.0),
    }
    return max(five_emotion_scores.items(), key=lambda x: x[1])[0]

def summarize_day_conversation(messages: List[str], user_id: str, date: str) -> Dict:
    combined_text = "\n".join(messages)

    prompt = f"""
ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ í•˜ë£¨ì¹˜ ëŒ€í™” ë‚´ìš©ì´ì•¼:

{combined_text}

[ì§€ì¹¨ ì‚¬í•­]
"summary"ëŠ” í•˜ë£¨ ìš”ì•½ëœ ë‚´ìš©ì„ ì‘ì„±ë˜ì–´ì•¼ í•´. 
ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë–¤ ê°ì •ë§Œ ëŠê¼‡ë‹¤ë¡œ ëë‚´ë©´ ì•ˆë˜ê³ , êµ¬ì²´ì ì¸ ë‚´ìš©ì´ ë°˜ì˜ë˜ë„ë¡ í•´ì•¼ í•´.
ë¬¸ì¥ ê¸¸ì´ëŠ” ì§§ìœ¼ë©´ ì•ˆë¼. ì‚¬ìš©ìê°€ í•˜ë£¨ì˜ ìì‹ ì˜ ê°ì •ì„ ë³´ê¸° ìœ„í•¨ì´ê¸° ë•Œë¬¸ì—
ìš”ì•½ëœ ë‚´ìš©ì´ë¼ í• ì§€ë¼ë„ ì „ì²´ì ì¸ ë‚´ìš©ì´ ì˜ ë°˜ì˜ë˜ì–´ ìˆì–´ì•¼í•´.

"feedback"ì€ ë§ ê·¸ëŒ€ë¡œ í”¼ë“œë°± í•´ì£¼ë©´ ë˜ëŠ”ë° ì˜ˆì‹œ ë¬¸ì¥ ì²˜ëŸ¼ ë„ˆë¬´ ì§§ê±°ë‚˜ ê·¸ëŸ¬ë©´ ì•ˆë¼.
ì‚¬ìš©ìì—ê²Œ ì§„ì‹¬ìœ¼ë¡œ ë„ì›€ì´ ë ë§Œí•œ í”¼ë“œë°±ì„ í•´ì¤˜ì•¼ í•´. 

"encouragement"ëŠ” ì˜¤ëŠ˜ "summary" ë‚´ìš©ê³¼ "feedback"ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì›ì˜ ë§ì´ë‚˜ ì‚¬ìš©ìì—ê²Œ
ë„ì›€ì´ ë˜ëŠ” ë§ì„ í•´ì¤˜. ìµœëŒ€ 3~4ë¬¸ì¥ìœ¼ë¡œ ëë‚´ë„ë¡ í•´ì¤˜ ë‚´ìš©ì´ ì§§ìœ¼ë©´ 1~2ë¬¸ì¥ìœ¼ë¡œ ëë‚´ë„ ì¢‹ì•„.

ê°ì • ë²¡í„° ì ìˆ˜ê°€ ë˜‘ê°™ì€ ìˆ«ìë¡œ ë‚˜ì˜¤ì§€ ì•ˆë„ë¡ í•´ì¤˜.

ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¶œë ¥í•´ì¤˜ (keyëŠ” ì˜ë¬¸, ê°’ì€ ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ê¹Œì§€):

ì˜ˆì‹œ:
{{
  "joy": 0.33,
  "sadness": 0.15,
  "anger": 0.10,
  "anxiety": 0.62,
  "stable": 0.33,
  "summary": "í•˜ë£¨ ë™ì•ˆ ë¶ˆì•ˆì´ ë§ì´ ëŠê»´ì¡Œê³ , ì§ì—…ì— ëŒ€í•œ ê±±ì •ì´ ì»¸ìŠµë‹ˆë‹¤.",
  "feedback": "ë¶ˆì•ˆí•  ë• í˜¸í¡ì„ ê°€ë‹¤ë“¬ê³  ì ì‹œ ì‚°ì±…ì„ í•´ë³´ì„¸ìš”.",
  "encouragement": "ì˜¤ëŠ˜ë„ ì˜ ë²„í…¨ì£¼ì…”ì„œ ê³ ë§ˆì›Œìš”."
}}
"""

    response = llm.invoke(prompt)
    raw_output = response.content.strip()
    print("ğŸ§  GPT ì‘ë‹µ ì›ë¬¸:\n", raw_output)

    if raw_output.startswith("```json"):
        raw_output = raw_output.lstrip("```json").rstrip("```").strip()
    elif raw_output.startswith("```"):
        raw_output = raw_output.lstrip("```").rstrip("```").strip()

    try:
        parsed = json.loads(raw_output)

        main_emotion = convert_to_main_emotion(parsed)

        return {
            "USER_ID": user_id,
            "DATE": date,
            "MAIN_EMOTION": main_emotion,
            "SCORE": max(parsed["joy"], parsed["sadness"], parsed["anger"], parsed["anxiety"]),
            "STABLE": parsed["stable"],
            "JOY": parsed["joy"],
            "SADNESS": parsed["sadness"],
            "ANGER": parsed["anger"],
            "ANXIETY": parsed["anxiety"],
            "SUMMARY": parsed["summary"],
            "FEEDBACK": parsed["feedback"],
            "ENCOURAGEMENT": parsed["encouragement"]
        }
    except Exception as e:
        print("GPT JSON íŒŒì‹± ì‹¤íŒ¨:", str(e))
        raise ValueError(f"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    

def get_emotion_trend_text(user_id: str, db: Session) -> str:


    today = datetime.now().date()
    week_ago = today - timedelta(days=6)

    reports = db.query(DailyEmotionReport).filter(
        DailyEmotionReport.USER_ID == user_id,
        DailyEmotionReport.DATE >= week_ago,
        DailyEmotionReport.DATE <= today
    ).order_by(DailyEmotionReport.DATE).all()

    if not reports or len(reports) < 2:
        return "ìµœê·¼ ê°ì • ë³€í™” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    lines = []
    for r in reports:
        lines.append(
            f"{r.DATE} â†’ ê¸°ì¨:{r.JOY:.2f}, ìŠ¬í””:{r.SADNESS:.2f}, ë¶ˆì•ˆ:{r.ANXIETY:.2f}, ì•ˆì •:{r.STABLE:.2f}, ë¶„ë…¸:{r.ANGER:.2f}"
        )

    return "\n".join(lines)


def get_user_nickname(user_id: str, db: Session) -> str:
    user = db.query(User).filter(User.USER_ID == user_id).first()
    return user.NICKNAME if user else "ì‚¬ìš©ìë‹˜"